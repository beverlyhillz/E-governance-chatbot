{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 104]\n",
      "[nltk_data]     Connection reset by peer>\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_test, vectorizer_path):\n",
    "    \"\"\"Performs TF-IDF transformation and dumps the model.\"\"\"\n",
    "    \n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=[1,2],min_df=5,max_df=0.9,token_pattern='(\\S+)')\n",
    "    tfidf_vectorizer.fit(X_train)\n",
    "    X_train=tfidf_vectorizer.transform(X_train)\n",
    "    X_test=tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "   \n",
    "    pickle.dump(tfidf_vectorizer, open(vectorizer_path, 'wb'))\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 310\n",
    "\n",
    "dialogue_df = pd.read_csv('data/dialogues.tsv', sep='\\t').sample(sample_size, random_state=0)\n",
    "questions_df = pd.read_csv('data/questions.csv', sep=',').sample(sample_size, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82925</th>\n",
       "      <td>Donna, you are a muffin.</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48774</th>\n",
       "      <td>He was here last night till about two o'clock....</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55394</th>\n",
       "      <td>All right, then make an appointment with her s...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90806</th>\n",
       "      <td>Hey, what is this-an interview? We're supposed...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107758</th>\n",
       "      <td>Yeah. He's just a friend of mine I was trying ...</td>\n",
       "      <td>dialogue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       tag\n",
       "82925                            Donna, you are a muffin.  dialogue\n",
       "48774   He was here last night till about two o'clock....  dialogue\n",
       "55394   All right, then make an appointment with her s...  dialogue\n",
       "90806   Hey, what is this-an interview? We're supposed...  dialogue\n",
       "107758  Yeah. He's just a friend of mine I was trying ...  dialogue"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>scheme</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>Varishtha Pension bima yojana</td>\n",
       "      <td>pension insurance</td>\n",
       "      <td>Who is offering the scheme</td>\n",
       "      <td>Life Insurance Corporation(LIC) India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>Pradhan Mantri Mudra Yojana</td>\n",
       "      <td>small business loan</td>\n",
       "      <td>Jurisdiction of scheme?</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Scheme For Liberation and Rehabilitation of Sc...</td>\n",
       "      <td>house loan</td>\n",
       "      <td>Nature</td>\n",
       "      <td>The objective of the scheme is to liberate the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>Pradhan Mantri Jeevan Jyoti BIMA Yojana</td>\n",
       "      <td>life insurance</td>\n",
       "      <td>Are PMJJBY policies being introduced and servi...</td>\n",
       "      <td>There are no foreign insurance Companies direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>Aam admi bima yojana</td>\n",
       "      <td>accident disablity death insurance</td>\n",
       "      <td>Introduction of the scheme</td>\n",
       "      <td>The Aam Aadmi Bima Yojana covers natural death...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id                                             scheme  \\\n",
       "294      294                      Varishtha Pension bima yojana   \n",
       "65        65                        Pradhan Mantri Mudra Yojana   \n",
       "15        15  Scheme For Liberation and Rehabilitation of Sc...   \n",
       "272      272            Pradhan Mantri Jeevan Jyoti BIMA Yojana   \n",
       "140      140                               Aam admi bima yojana   \n",
       "\n",
       "                               category  \\\n",
       "294                   pension insurance   \n",
       "65                  small business loan   \n",
       "15                           house loan   \n",
       "272                      life insurance   \n",
       "140  accident disablity death insurance   \n",
       "\n",
       "                                                 title  \\\n",
       "294                         Who is offering the scheme   \n",
       "65                             Jurisdiction of scheme?   \n",
       "15                                              Nature   \n",
       "272  Are PMJJBY policies being introduced and servi...   \n",
       "140                         Introduction of the scheme   \n",
       "\n",
       "                                                answer  \n",
       "294              Life Insurance Corporation(LIC) India  \n",
       "65                                             Central  \n",
       "15   The objective of the scheme is to liberate the...  \n",
       "272  There are no foreign insurance Companies direc...  \n",
       "140  The Aam Aadmi Bima Yojana covers natural death...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import text_prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=text_prepare('What is the purpose of pradhan mantri mudra yojna?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_df['text'] = [text_prepare(x) for x in dialogue_df['text']]\n",
    "questions_df['title'] = [text_prepare(x) for x in questions_df['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>scheme</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>Varishtha Pension bima yojana</td>\n",
       "      <td>pension insurance</td>\n",
       "      <td>offering scheme</td>\n",
       "      <td>Life Insurance Corporation(LIC) India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>Pradhan Mantri Mudra Yojana</td>\n",
       "      <td>small business loan</td>\n",
       "      <td>jurisdiction scheme</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Scheme For Liberation and Rehabilitation of Sc...</td>\n",
       "      <td>house loan</td>\n",
       "      <td>nature</td>\n",
       "      <td>The objective of the scheme is to liberate the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>Pradhan Mantri Jeevan Jyoti BIMA Yojana</td>\n",
       "      <td>life insurance</td>\n",
       "      <td>pmjjby policies introduced serviced associatio...</td>\n",
       "      <td>There are no foreign insurance Companies direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>Aam admi bima yojana</td>\n",
       "      <td>accident disablity death insurance</td>\n",
       "      <td>introduction scheme</td>\n",
       "      <td>The Aam Aadmi Bima Yojana covers natural death...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id                                             scheme  \\\n",
       "294      294                      Varishtha Pension bima yojana   \n",
       "65        65                        Pradhan Mantri Mudra Yojana   \n",
       "15        15  Scheme For Liberation and Rehabilitation of Sc...   \n",
       "272      272            Pradhan Mantri Jeevan Jyoti BIMA Yojana   \n",
       "140      140                               Aam admi bima yojana   \n",
       "\n",
       "                               category  \\\n",
       "294                   pension insurance   \n",
       "65                  small business loan   \n",
       "15                           house loan   \n",
       "272                      life insurance   \n",
       "140  accident disablity death insurance   \n",
       "\n",
       "                                                 title  \\\n",
       "294                                    offering scheme   \n",
       "65                                 jurisdiction scheme   \n",
       "15                                              nature   \n",
       "272  pmjjby policies introduced serviced associatio...   \n",
       "140                                introduction scheme   \n",
       "\n",
       "                                                answer  \n",
       "294              Life Insurance Corporation(LIC) India  \n",
       "65                                             Central  \n",
       "15   The objective of the scheme is to liberate the...  \n",
       "272  There are no foreign insurance Companies direc...  \n",
       "140  The Aam Aadmi Bima Yojana covers natural death...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 558, test size = 62\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([dialogue_df['text'].values, questions_df['title'].values])\n",
    "y = ['dialogue'] * dialogue_df.shape[0] + ['questions'] * questions_df.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "print('Train size = {}, test size = {}'.format(len(X_train), len(X_test)))\n",
    "\n",
    "X_train_tfidf, X_test_tfidf = tfidf_features(X_train, X_test, RESOURCE_PATH['TFIDF_VECTORIZER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8924731182795699"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_recognizer=LogisticRegression(penalty='l2',C=10, random_state=0).fit(X_train_tfidf, y_train)\n",
    "accuracy_score(y_train, intent_recognizer.predict(X_train_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.8870967741935484\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = intent_recognizer.predict(X_test_tfidf)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print('Test accuracy = {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(intent_recognizer, open(RESOURCE_PATH['INTENT_RECOGNIZER'], 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = questions_df['answer'].values\n",
    "#y1 = questions_df['category'].values\n",
    "#y2 = questions_df['scheme'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y1, test_size=0.2, random_state=0)\n",
    "#X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y2, test_size=0.2, random_state=0)\n",
    "#print('Train size = {}, test size = {}'.format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = pickle.load(open(RESOURCE_PATH['TFIDF_VECTORIZER'], 'rb'))\n",
    "\n",
    "#X_train1_tfidf, X_test1_tfidf = vectorizer.transform(X_train1.astype('U')), vectorizer.transform(X_test1.astype('U'))\n",
    "#X_train2_tfidf, X_test2_tfidf = vectorizer.transform(X_train2.astype('U')), vectorizer.transform(X_test2.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category_classifier= OneVsRestClassifier(LogisticRegression(penalty='l2', C=5, random_state=0)).fit(X_train1_tfidf, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scheme_classifier= OneVsRestClassifier(LogisticRegression(penalty='l2', C=5, random_state=0)).fit(X_train2_tfidf, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Check test accuracy.\\ny_test1_pred = category_classifier.predict(X_test_tfidf)\\ntest1_accuracy = accuracy_score(y_test1, y_test1_pred)\\nprint('Test1 accuracy = {}'.format(test1_accuracy))\\n# Check test accuracy.\\ny_test2_pred = scheme_classifier.predict(X_test_tfidf)\\ntest2_accuracy = accuracy_score(y_test2, y_test2_pred)\\nprint('Test2 accuracy = {}'.format(test2_accuracy))\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Check test accuracy.\n",
    "y_test1_pred = category_classifier.predict(X_test_tfidf)\n",
    "test1_accuracy = accuracy_score(y_test1, y_test1_pred)\n",
    "print('Test1 accuracy = {}'.format(test1_accuracy))\n",
    "# Check test accuracy.\n",
    "y_test2_pred = scheme_classifier.predict(X_test_tfidf)\n",
    "test2_accuracy = accuracy_score(y_test2, y_test2_pred)\n",
    "print('Test2 accuracy = {}'.format(test2_accuracy))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pickle.dump(category_classifier, open(RESOURCE_PATH['CATEGORY_CLASSIFIER'], 'wb'))\\npickle.dump(scheme_classifier, open(RESOURCE_PATH['SCHEME_CLASSIFIER'], 'wb'))\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"pickle.dump(category_classifier, open(RESOURCE_PATH['CATEGORY_CLASSIFIER'], 'wb'))\n",
    "pickle.dump(scheme_classifier, open(RESOURCE_PATH['SCHEME_CLASSIFIER'], 'wb'))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gensim\n",
    "word_embeddings = gensim.models.KeyedVectors.load_word2vec_format(fname=\"data/GoogleNews-vectors-negative300.bin\",binary=True,limit=500000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi={'awas':'home','pradhan':'prime','mantri':'minister','yojana':'scheme','aam':'normal','admi':'man','bima':'insurance','varishtha':'old','vaya':'age','vandana':'prayer','jeevan':'life','jyoti':'light','fasal':'crop','suraksha':'security','jan':'people','dhan':'money','arogya':'health','mudra':'currency','rojgar':'employment','swasthya':'health','rastriya':'national'}\n",
    "for i in hindi.keys():\n",
    "    word_embeddings[i]=word_embeddings[hindi[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = questions_df['scheme'].unique()\n",
    "Cat = questions_df['category'].unique()\n",
    "New=[]\n",
    "for c in X:\n",
    "    New.append(c)\n",
    "for c in Cat:\n",
    "    New.append(c)\n",
    "Q=[text_prepare(x) for x in New]\n",
    "import string\n",
    "st=string.ascii_lowercase\n",
    "chemd={}\n",
    "for i in st:\n",
    "    chemd[i]=[int(j==i) for j in st]\n",
    "a=[]\n",
    "for i in Q:\n",
    "    for j in i.split():\n",
    "        a.append(j)\n",
    "a=[i for i in set(a)]\n",
    "d=[]\n",
    "for j in a:\n",
    "    s=np.zeros(26)\n",
    "    for i in j:\n",
    "        s=s+chemd[i]\n",
    "    d.append(s/len(j))\n",
    "def question_to_vec_char(question, embeddings, dim):\n",
    "    \"\"\"Transforms a string to an embedding by averaging word embeddings.\"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "    arr=question.split()\n",
    "    vec = np.zeros(dim)\n",
    "    i=0\n",
    "    for word in arr:\n",
    "        if word in embeddings:\n",
    "            vec+=embeddings[word]\n",
    "            i+=1\n",
    "        else:\n",
    "            best_scheme = np.argmax(cosine_similarity(s, d)[0])\n",
    "            \n",
    "            if a[best_scheme] in embeddings:\n",
    "                vec=vec+embeddings[a[best_scheme]]\n",
    "                i+=1\n",
    "    if i!=0:\n",
    "        return vec/i\n",
    "    else:\n",
    "        return vec\n",
    "s=wrd2vec('primr')\n",
    "best_scheme = np.argmax(cosine_similarity(s, d)[0])\n",
    "a[best_scheme]\n",
    "R=[]\n",
    "for sch in Q:\n",
    "    arr=sch.split()\n",
    "    vec = np.zeros(300)\n",
    "    i=0\n",
    "    for word in arr:\n",
    "        if word in word_embeddings:\n",
    "            vec=vec+word_embeddings[word]\n",
    "            i+=1\n",
    "            \n",
    "    if i!=0:\n",
    "        vec= vec/i\n",
    "    R.append(vec)\n",
    "def predict (inp):\n",
    "    W=question_to_vec_char(inp, word_embeddings, 300).reshape(1,-1)\n",
    "    best_scheme = np.argmax(cosine_similarity(W, R)[0])\n",
    "    return (Q[best_scheme])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scheme_classifier, open(RESOURCE_PATH['SCHEME_CLASSIFIER'], 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "finalembed_df=pd.read_csv(\"dictionary.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'apy' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a1f5ca5da0e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcsvData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinalembed_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcsvData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'person.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'apy' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "csvData=[]\n",
    "for i in finalembed_df['word']:\n",
    "    if i.lower() in word_embeddings:\n",
    "        csvData.append(word_embeddings[i.lower()])  \n",
    "    \n",
    "with open('person.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(csvData)\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "starspace_embeddings, embeddings_dim = load_embeddings('data/word_embeddings.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = pd.read_csv('data/questions.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_category = posts_df.groupby('category').count()['title']\n",
    "counts_by_scheme = posts_df.groupby('scheme').count()['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(RESOURCE_PATH['SCHEME_EMBEDDINGS_FOLDER'], exist_ok=True)\n",
    "\n",
    "for scheme, count in counts_by_scheme.items():\n",
    "    scheme_posts = posts_df[posts_df['scheme'] == scheme]\n",
    "    \n",
    "    scheme_post_ids = scheme_posts['post_id'].tolist()\n",
    "    \n",
    "    scheme_vectors = np.zeros((count, embeddings_dim), dtype=np.float32)\n",
    "    for i, title in enumerate(scheme_posts['title']):\n",
    "        scheme_vectors[i, :] = question_to_vec(title, starspace_embeddings, embeddings_dim)\n",
    "\n",
    "    # Dump post ids and vectors to a file.\n",
    "    filename = os.path.join(RESOURCE_PATH['SCHEME_EMBEDDINGS_FOLDER'], os.path.normpath('%s.pkl' % scheme.lower()))\n",
    "    pickle.dump((scheme_post_ids, scheme_vectors), open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(RESOURCE_PATH['CATEGORY_EMBEDDINGS_FOLDER'], exist_ok=True)\n",
    "\n",
    "for category, count in counts_by_category.items():\n",
    "    category_posts = posts_df[posts_df['category'] == category]\n",
    "    \n",
    "    category_post_ids = category_posts['post_id'].tolist()\n",
    "    \n",
    "    category_vectors = np.zeros((count, embeddings_dim), dtype=np.float32)\n",
    "    for i, title in enumerate(category_posts['title']):\n",
    "        category_vectors[i, :] = question_to_vec(title, starspace_embeddings, embeddings_dim)\n",
    "\n",
    "    # Dump post ids and vectors to a file.\n",
    "    filename = os.path.join(RESOURCE_PATH['CATEGORY_EMBEDDINGS_FOLDER'], os.path.normpath('%s.pkl' % category.lower()))\n",
    "    pickle.dump((category_post_ids, category_vectors), open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
